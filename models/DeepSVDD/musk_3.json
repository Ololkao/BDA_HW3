{"class_name": "Functional", "config": {"name": "model_26", "layers": [{"class_name": "InputLayer", "config": {"batch_input_shape": [null, 2], "dtype": "float32", "sparse": false, "ragged": false, "name": "input_18"}, "name": "input_18", "inbound_nodes": []}, {"class_name": "Dense", "config": {"name": "dense_115", "trainable": true, "dtype": "float32", "units": 830, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_115", "inbound_nodes": [[["input_18", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "dense_116", "trainable": true, "dtype": "float32", "units": 3320, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_116", "inbound_nodes": [[["dense_115", 0, 0, {}]]]}, {"class_name": "Dropout", "config": {"name": "dropout_89", "trainable": true, "dtype": "float32", "rate": 0.2, "noise_shape": null, "seed": null}, "name": "dropout_89", "inbound_nodes": [[["dense_116", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "net_output", "trainable": true, "dtype": "float32", "units": 830, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "net_output", "inbound_nodes": [[["dropout_89", 0, 0, {}]]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.subtract_17", "trainable": true, "dtype": "float32", "function": "math.subtract"}, "name": "tf.math.subtract_17", "inbound_nodes": [["net_output", 0, 0, {"y": [0.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.18776719272136688, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2758373022079468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.20711667835712433, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.19149914383888245, 0.22373081743717194, 0.10000000149011612, 0.4375557601451874, 0.13540104031562805, 0.0, 0.0, 0.0, 0.2912701666355133, 0.10000000149011612, 0.10000000149011612, 0.6328514218330383, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.4200823903083801, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.29210931062698364, 0.2871856689453125, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.3089067339897156, 0.10000000149011612, 0.21399304270744324, 0.24740375578403473, 0.10000000149011612, 0.10000000149011612, 0.0, 0.4082038700580597, 0.10000000149011612, 0.28156882524490356, 0.10000000149011612, 0.10000000149011612, 0.0, 0.11055167764425278, 0.10000000149011612, 0.12124695628881454, 0.16406236588954926, 0.11065780371427536, 0.10000000149011612, 0.10266938805580139, 0.0, 0.10000000149011612, 0.20479285717010498, 0.19418373703956604, 0.31142401695251465, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.2570822536945343, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1799919456243515, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.11702901870012283, 0.0, 0.10000000149011612, 0.10000000149011612, 0.15881715714931488, 0.10000000149011612, 0.10000000149011612, 0.24297218024730682, 0.10000000149011612, 0.10000000149011612, 0.0, 0.12769579887390137, 0.10000000149011612, 0.0, 0.14813725650310516, 0.11964429914951324, 0.2749382257461548, 0.2906019687652588, 0.10000000149011612, 0.0, 0.10307762771844864, 0.18741358816623688, 0.12927894294261932, 0.19080185890197754, 0.10000000149011612, 0.0, 0.150991290807724, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.12036500126123428, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.15327584743499756, 0.10000000149011612, 0.37802377343177795, 0.10000000149011612, 0.10000000149011612, 0.0, 0.14014624059200287, 0.0, 0.10602276027202606, 0.11987480521202087, 0.100537970662117, 0.10000000149011612, 0.10000000149011612, 0.1279067099094391, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.11551124602556229, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.22872763872146606, 0.0, 0.12469422817230225, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.18474487960338593, 0.2197890728712082, 0.22313135862350464, 0.0, 0.10089865326881409, 0.2090088278055191, 0.2027410864830017, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.15848752856254578, 0.13063782453536987, 0.13718152046203613, 0.35181868076324463, 0.12990954518318176, 0.0, 0.15277472138404846, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.30059799551963806, 0.10000000149011612, 0.10199989378452301, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.4401877522468567, 0.0, 0.15518534183502197, 0.10000000149011612, 0.10000000149011612, 0.19129100441932678, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10805045813322067, 0.1924576610326767, 0.10000000149011612, 0.13140533864498138, 0.10349816083908081, 0.47491949796676636, 0.20121000707149506, 0.0, 0.10000000149011612, 0.1367926150560379, 0.10113798081874847, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.2080368995666504, 0.21753373742103577, 0.0, 0.0, 0.17912402749061584, 0.19753392040729523, 0.0, 0.10000000149011612, 0.10000000149011612, 0.6364920735359192, 0.11983790248632431, 0.0, 0.0, 0.10000000149011612, 0.10005466639995575, 0.0, 0.10000000149011612, 0.11126518994569778, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.2534540593624115, 0.0, 0.32545530796051025, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.39310985803604126, 0.37290188670158386, 0.11120054125785828, 0.10000000149011612, 0.20627541840076447, 0.0, 0.10000000149011612, 0.10000000149011612, 0.22378817200660706, 0.10000000149011612, 0.0, 0.10000000149011612, 0.2876821756362915, 0.2333168387413025, 0.10000000149011612, 0.3920591473579407, 0.19973887503147125, 0.2811828553676605, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.12935389578342438, 0.13161203265190125, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2849111557006836, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10386329889297485, 0.10000000149011612, 0.10000000149011612, 0.2158471643924713, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.33916378021240234, 0.0, 0.0, 0.30076390504837036, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.20292024314403534, 0.0, 0.0, 0.0, 0.14790773391723633, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.2988947629928589, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.1451682150363922, 0.10000000149011612, 0.10000000149011612, 0.1359703242778778, 0.21255595982074738, 0.10000000149011612, 0.2272375375032425, 0.10000000149011612, 0.1734572798013687, 0.14389581978321075, 0.1243492066860199, 0.12458421289920807, 0.1400441825389862, 0.3337021768093109, 0.0, 0.11018037050962448, 0.2850760817527771, 0.1771358996629715, 0.10000000149011612, 0.10395419597625732, 0.22214360535144806, 0.10000000149011612, 0.0, 0.0, 0.0, 0.2970784306526184, 0.10000000149011612, 0.17389851808547974, 0.0, 0.10000000149011612, 0.2583044767379761, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.12043020874261856, 0.10000000149011612, 0.13781195878982544, 0.10000000149011612, 0.10000000149011612, 0.0, 0.37282299995422363, 0.0, 0.10000000149011612, 0.3306778371334076, 0.0, 0.11395810544490814, 0.10339099168777466, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.30050939321517944, 0.24486124515533447, 0.26634418964385986, 0.4201945662498474, 0.16290457546710968, 0.10000000149011612, 0.10000000149011612, 0.0, 0.29775741696357727, 0.4961048364639282, 0.11902251839637756, 0.13193392753601074, 0.10000000149011612, 0.4217122197151184, 0.10000000149011612, 0.10000000149011612, 0.0, 0.214244082570076, 0.13680225610733032, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2214014083147049, 0.11015673726797104, 0.10991213470697403, 0.10000000149011612, 0.1702404022216797, 0.16735154390335083, 0.10000000149011612, 0.11629574745893478, 0.10000000149011612, 0.0, 0.19117438793182373, 0.10000000149011612, 0.10000000149011612, 0.20548920333385468, 0.13697560131549835, 0.30419519543647766, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2658067047595978, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10303416848182678, 0.0, 0.15073871612548828, 0.0, 0.10000000149011612, 0.18654118478298187, 0.24975170195102692, 0.0, 0.0, 0.3960665464401245, 0.24147219955921173, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.13895238935947418, 0.10000000149011612, 0.0, 0.10000000149011612, 0.16754597425460815, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.21421948075294495, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.17802871763706207, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.19729334115982056, 0.38205820322036743, 0.10000000149011612, 0.2133704274892807, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.31483641266822815, 0.16442298889160156, 0.0, 0.14799544215202332, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.21342486143112183, 0.10000000149011612, 0.19822540879249573, 0.10000000149011612, 0.0, 0.0, 0.20360314846038818, 0.10000000149011612, 0.24548572301864624, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.11065597832202911, 0.0, 0.12675078213214874, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.44814640283584595, 0.18680226802825928, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.30620208382606506, 0.1765783578157425, 0.0, 0.0, 0.0, 0.10000000149011612, 0.3503810465335846, 0.0, 0.0, 0.0, 0.18336978554725647, 0.10000000149011612, 0.0, 0.29137855768203735, 0.12359427660703659, 0.34023910760879517, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.1786957085132599, 0.10000000149011612, 0.0, 0.10000000149011612, 0.22778891026973724, 0.0, 0.1699514538049698, 0.10000000149011612, 0.10000000149011612, 0.0, 0.1454586237668991, 0.10000000149011612, 0.12751346826553345, 0.10000000149011612, 0.13240595161914825, 0.1950816661119461, 0.0, 0.10000000149011612, 0.10000000149011612, 0.29301393032073975, 0.25690481066703796, 0.10000000149011612, 0.0, 0.3957054018974304, 0.33981531858444214, 0.0, 0.38815200328826904, 0.10000000149011612, 0.15118467807769775, 0.3110380470752716, 0.10000000149011612, 0.0, 0.0, 0.25139713287353516, 0.2505616247653961, 0.10000000149011612, 0.10000000149011612, 0.21035970747470856, 0.20854593813419342, 0.11466513574123383, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.16894124448299408, 0.10000000149011612, 0.10000000149011612, 0.10343693941831589, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.24851132929325104, 0.2087114155292511, 0.24144822359085083, 0.0, 0.0, 0.10000000149011612, 0.16865594685077667, 0.0, 0.15587815642356873, 0.2057429999113083, 0.10000000149011612, 0.126753568649292, 0.33012375235557556, 0.10000000149011612, 0.3436054587364197, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.209096759557724, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1724756360054016, 0.14000533521175385, 0.11614043265581131, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.22201167047023773, 0.12884530425071716, 0.0, 0.2745674252510071, 0.3121199905872345, 0.11678899824619293, 0.6228085160255432, 0.10000000149011612, 0.12868967652320862, 0.10000000149011612, 0.2424883097410202, 0.10000000149011612, 0.12948289513587952, 0.0, 0.10000000149011612, 0.4280816614627838, 0.0, 0.0, 0.20381423830986023, 0.10000000149011612, 0.0, 0.10000000149011612, 0.13510380685329437, 0.10000000149011612, 0.0, 0.0, 0.41381362080574036, 0.10000000149011612, 0.3821186125278473, 0.0, 0.2768136262893677, 0.4271250367164612, 0.3197888433933258, 0.0, 0.3434351980686188, 0.10000000149011612, 0.10000000149011612, 0.0, 0.12930311262607574, 0.17894934117794037, 0.10000000149011612, 0.43817752599716187, 0.12536151707172394, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.35500574111938477, 0.10000000149011612, 0.10000000149011612, 0.0, 0.12077248096466064, 0.1821443885564804, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.3054404854774475, 0.0, 0.10000000149011612, 0.10503220558166504, 0.0, 0.10000000149011612, 0.0, 0.33560192584991455, 0.10000000149011612, 0.10000000149011612, 0.1818659007549286, 0.10000000149011612, 0.10000000149011612, 0.0, 0.35229527950286865, 0.14925646781921387, 0.10000000149011612, 0.14012624323368073, 0.0, 0.10000000149011612, 0.0, 0.0, 0.22665347158908844, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.33273085951805115, 0.10000000149011612, 0.15946264564990997, 0.23428066074848175, 0.10000000149011612, 0.49407556653022766, 0.11905233561992645, 0.2879529893398285, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1260661482810974, 0.0, 0.10000000149011612, 0.2593502402305603, 0.10000000149011612, 0.10000000149011612, 0.18907898664474487, 0.23500177264213562, 0.1410648673772812, 0.0, 0.10000000149011612, 0.10000000149011612, 0.1728285849094391, 0.10000000149011612, 0.10000000149011612, 0.11964543908834457, 0.17521122097969055, 0.0, 0.10461010783910751, 0.23013685643672943, 0.20015360414981842, 0.0, 0.449249267578125, 0.0, 0.1112152636051178, 0.10000000149011612, 0.18728268146514893, 0.2851616144180298, 0.10000000149011612, 0.24624811112880707, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.11189848929643631, 0.10000000149011612, 0.0, 0.1430904120206833, 0.0, 0.0, 0.18831488490104675, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.22410324215888977, 0.10000000149011612, 0.12571170926094055, 0.0, 0.10000000149011612, 0.12645433843135834, 0.16686952114105225, 0.21650545299053192, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.10000000149011612, 0.15347391366958618, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.12598517537117004, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10692625492811203, 0.0, 0.10000000149011612, 0.18075090646743774, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.15992556512355804], "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.pow_17", "trainable": true, "dtype": "float32", "function": "math.pow"}, "name": "tf.math.pow_17", "inbound_nodes": [["tf.math.subtract_17", 0, 0, {"y": 2, "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_sum_17", "trainable": true, "dtype": "float32", "function": "math.reduce_sum"}, "name": "tf.math.reduce_sum_17", "inbound_nodes": [["tf.math.pow_17", 0, 0, {"axis": -1}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_mean_17", "trainable": true, "dtype": "float32", "function": "math.reduce_mean"}, "name": "tf.math.reduce_mean_17", "inbound_nodes": [["tf.math.reduce_sum_17", 0, 0, {}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.__operators__.add_17", "trainable": true, "dtype": "float32", "function": "__operators__.add"}, "name": "tf.__operators__.add_17", "inbound_nodes": [["tf.math.reduce_mean_17", 0, 0, {"y": 7.484910881519317e-05, "name": null}]]}, {"class_name": "AddLoss", "config": {"name": "add_loss_17", "trainable": true, "dtype": "float32", "unconditional": false}, "name": "add_loss_17", "inbound_nodes": [[["tf.__operators__.add_17", 0, 0, {}]]]}], "input_layers": [["input_18", 0, 0]], "output_layers": [["tf.math.reduce_sum_17", 0, 0]]}, "keras_version": "2.6.0", "backend": "tensorflow"}
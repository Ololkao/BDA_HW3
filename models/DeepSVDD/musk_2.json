{"class_name": "Functional", "config": {"name": "model_23", "layers": [{"class_name": "InputLayer", "config": {"batch_input_shape": [null, 2], "dtype": "float32", "sparse": false, "ragged": false, "name": "input_16"}, "name": "input_16", "inbound_nodes": []}, {"class_name": "Dense", "config": {"name": "dense_102", "trainable": true, "dtype": "float32", "units": 830, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_102", "inbound_nodes": [[["input_16", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "dense_103", "trainable": true, "dtype": "float32", "units": 3320, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_103", "inbound_nodes": [[["dense_102", 0, 0, {}]]]}, {"class_name": "Dropout", "config": {"name": "dropout_79", "trainable": true, "dtype": "float32", "rate": 0.2, "noise_shape": null, "seed": null}, "name": "dropout_79", "inbound_nodes": [[["dense_103", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "net_output", "trainable": true, "dtype": "float32", "units": 830, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "net_output", "inbound_nodes": [[["dropout_79", 0, 0, {}]]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.subtract_15", "trainable": true, "dtype": "float32", "function": "math.subtract"}, "name": "tf.math.subtract_15", "inbound_nodes": [["net_output", 0, 0, {"y": [0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.27910685539245605, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2625163197517395, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1798403263092041, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2091887891292572, 0.24780482053756714, 0.10000000149011612, 0.438692569732666, 0.10000000149011612, 0.0, 0.0, 0.13079127669334412, 0.28983402252197266, 0.10000000149011612, 0.10000000149011612, 0.5066789388656616, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.4115302562713623, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.13400664925575256, 0.2783847451210022, 0.3075034022331238, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2738918364048004, 0.0, 0.1550239622592926, 0.16109910607337952, 0.0, 0.10000000149011612, 0.0, 0.3834502398967743, 0.10000000149011612, 0.2227468192577362, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.22659434378147125, 0.1222805604338646, 0.10656838119029999, 0.11941912025213242, 0.0, 0.14518600702285767, 0.24984148144721985, 0.16174645721912384, 0.31537166237831116, 0.0, 0.0, 0.10000000149011612, 0.13867618143558502, 0.23673425614833832, 0.10131096094846725, 0.10000000149011612, 0.10000000149011612, 0.13715782761573792, 0.15113972127437592, 0.0, 0.10000000149011612, 0.1381918489933014, 0.0, 0.0, 0.10000000149011612, 0.1592533141374588, 0.21929235756397247, 0.0, 0.18670113384723663, 0.0, 0.10000000149011612, 0.0, 0.17286564409732819, 0.10000000149011612, 0.0, 0.14779424667358398, 0.10000000149011612, 0.18733833730220795, 0.13751202821731567, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.16038981080055237, 0.11135054379701614, 0.10000000149011612, 0.0, 0.13021640479564667, 0.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.11292087286710739, 0.0, 0.0, 0.12771570682525635, 0.10000000149011612, 0.3827489912509918, 0.10000000149011612, 0.10000000149011612, 0.0, 0.15159456431865692, 0.0, 0.1354113519191742, 0.11511664092540741, 0.10535147786140442, 0.12876485288143158, 0.10000000149011612, 0.16564640402793884, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1036345437169075, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.15877383947372437, 0.0, 0.1285930871963501, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.19142061471939087, 0.25396496057510376, 0.15968678891658783, 0.10000000149011612, 0.12157969921827316, 0.1378350704908371, 0.18829825520515442, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.17869822680950165, 0.15136362612247467, 0.10000000149011612, 0.3957798480987549, 0.10000000149011612, 0.0, 0.1148601546883583, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.3609638214111328, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.5080587267875671, 0.0, 0.27478429675102234, 0.0, 0.10000000149011612, 0.17171873152256012, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.2343348264694214, 0.10000000149011612, 0.1377691626548767, 0.10000000149011612, 0.5566496849060059, 0.1671675443649292, 0.0, 0.10000000149011612, 0.15354639291763306, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.24006816744804382, 0.19180907309055328, 0.0, 0.10000000149011612, 0.13548418879508972, 0.15228046476840973, 0.0, 0.10000000149011612, 0.10000000149011612, 0.6243990063667297, 0.11816275119781494, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.165620356798172, 0.10000000149011612, 0.20724494755268097, 0.10000000149011612, 0.0, 0.10000000149011612, 0.24657095968723297, 0.10000000149011612, 0.4440237283706665, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.0, 0.3374214172363281, 0.31302884221076965, 0.15737192332744598, 0.10000000149011612, 0.2065819799900055, 0.0, 0.10000000149011612, 0.0, 0.18173132836818695, 0.10000000149011612, 0.0, 0.0, 0.19881217181682587, 0.13535529375076294, 0.21716347336769104, 0.34011775255203247, 0.32316476106643677, 0.29475048184394836, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.1128079816699028, 0.10000000149011612, 0.13173486292362213, 0.10000000149011612, 0.10000000149011612, 0.12795807421207428, 0.10000000149011612, 0.24166323244571686, 0.10000000149011612, 0.10226438194513321, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.14409223198890686, 0.25922390818595886, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.38466668128967285, 0.0, 0.0, 0.3864908516407013, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.1402883380651474, 0.0, 0.0, 0.0, 0.22833606600761414, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.24525263905525208, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.0, 0.15667946636676788, 0.10000000149011612, 0.10000000149011612, 0.14469660818576813, 0.14721916615962982, 0.10000000149011612, 0.0, 0.10000000149011612, 0.1989837884902954, 0.10347426682710648, 0.30867093801498413, 0.10000000149011612, 0.19220781326293945, 0.16880370676517487, 0.10000000149011612, 0.12929655611515045, 0.14628586173057556, 0.2909446060657501, 0.0, 0.14976021647453308, 0.28190377354621887, 0.10000000149011612, 0.11456643790006638, 0.11392894387245178, 0.17825105786323547, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2724069058895111, 0.12222950160503387, 0.15762612223625183, 0.10000000149011612, 0.0, 0.2280266433954239, 0.10000000149011612, 0.10000000149011612, 0.0, 0.11216302216053009, 0.10000000149011612, 0.0, 0.10449519008398056, 0.10000000149011612, 0.10000000149011612, 0.0, 0.3745286762714386, 0.10000000149011612, 0.10000000149011612, 0.27922767400741577, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.47658592462539673, 0.24605195224285126, 0.21833577752113342, 0.32366132736206055, 0.158797025680542, 0.10000000149011612, 0.10000000149011612, 0.0, 0.20695942640304565, 0.32775506377220154, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.41291654109954834, 0.10000000149011612, 0.0, 0.0, 0.14200955629348755, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.12181258946657181, 0.10000000149011612, 0.17477844655513763, 0.1965046525001526, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1414041370153427, 0.12559647858142853, 0.10000000149011612, 0.2613649368286133, 0.1806185096502304, 0.20767493546009064, 0.10000000149011612, 0.0, 0.10000000149011612, 0.17847588658332825, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.11807162314653397, 0.0, 0.10000000149011612, 0.10000000149011612, 0.3121614456176758, 0.0, 0.10000000149011612, 0.3493853211402893, 0.2825515866279602, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.11940442770719528, 0.10000000149011612, 0.0, 0.11170244961977005, 0.10000000149011612, 0.0, 0.0, 0.0, 0.3453911542892456, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.12950937449932098, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.14196059107780457, 0.33570802211761475, 0.1027146652340889, 0.21257781982421875, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10653536021709442, 0.33157315850257874, 0.1363556832075119, 0.0, 0.22131849825382233, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.13081839680671692, 0.1311512589454651, 0.11951716989278793, 0.10000000149011612, 0.10000000149011612, 0.0, 0.19416658580303192, 0.10000000149011612, 0.20418760180473328, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.18123118579387665, 0.10000000149011612, 0.10000000149011612, 0.0, 0.37411201000213623, 0.24412283301353455, 0.10000000149011612, 0.10000000149011612, 0.18184153735637665, 0.17638303339481354, 0.14096620678901672, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.4021306037902832, 0.0, 0.0, 0.0, 0.17917793989181519, 0.14792503416538239, 0.0, 0.23637188971042633, 0.16137106716632843, 0.3171273171901703, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.12066624313592911, 0.10000000149011612, 0.0, 0.10000000149011612, 0.16335703432559967, 0.10000000149011612, 0.12745316326618195, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2607262134552002, 0.10000000149011612, 0.10000000149011612, 0.0, 0.14953579008579254, 0.13133005797863007, 0.0, 0.10000000149011612, 0.10000000149011612, 0.19269023835659027, 0.23250418901443481, 0.10000000149011612, 0.0, 0.35601580142974854, 0.3000873625278473, 0.0, 0.2635212540626526, 0.10000000149011612, 0.11869686841964722, 0.15068618953227997, 0.10000000149011612, 0.10000000149011612, 0.0, 0.3183123469352722, 0.20523589849472046, 0.11767200380563736, 0.10000000149011612, 0.11076369136571884, 0.19363513588905334, 0.17470233142375946, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10688944160938263, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1016252413392067, 0.10000000149011612, 0.10000000149011612, 0.22766563296318054, 0.19292491674423218, 0.20849862694740295, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10764794796705246, 0.1978103369474411, 0.0, 0.19615748524665833, 0.3230256736278534, 0.10000000149011612, 0.2998330295085907, 0.0, 0.0, 0.10000000149011612, 0.0, 0.14122441411018372, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.14908906817436218, 0.1588902473449707, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.1977723240852356, 0.1941339522600174, 0.10000000149011612, 0.25900986790657043, 0.17838017642498016, 0.10000000149011612, 0.632265031337738, 0.10000000149011612, 0.12278327345848083, 0.0, 0.1292969137430191, 0.0, 0.10000000149011612, 0.0, 0.0, 0.5149028301239014, 0.0, 0.10000000149011612, 0.22053952515125275, 0.10000000149011612, 0.0, 0.10000000149011612, 0.24634148180484772, 0.10000000149011612, 0.10000000149011612, 0.0, 0.5475067496299744, 0.10000000149011612, 0.2961052358150482, 0.10000000149011612, 0.1360907256603241, 0.4372822642326355, 0.28792133927345276, 0.0, 0.3168313205242157, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.25472313165664673, 0.10000000149011612, 0.4394643306732178, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25005054473876953, 0.10000000149011612, 0.0, 0.10000000149011612, 0.14632637798786163, 0.1310257911682129, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2115013599395752, 0.0, 0.0, 0.23679567873477936, 0.0, 0.10000000149011612, 0.0, 0.3702937066555023, 0.10000000149011612, 0.0, 0.23651136457920074, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2862797975540161, 0.13042104244232178, 0.10000000149011612, 0.1741906851530075, 0.0, 0.0, 0.0, 0.0, 0.19929181039333344, 0.15275530517101288, 0.0, 0.0, 0.10000000149011612, 0.35806137323379517, 0.10000000149011612, 0.10000000149011612, 0.21846924722194672, 0.10000000149011612, 0.4932717978954315, 0.16599194705486298, 0.1384362131357193, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.21678894758224487, 0.10000000149011612, 0.0, 0.22231706976890564, 0.2308720201253891, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.13767898082733154, 0.0, 0.13651342689990997, 0.17323999106884003, 0.13881714642047882, 0.0, 0.10000000149011612, 0.139146089553833, 0.2297670841217041, 0.0, 0.4374050199985504, 0.10000000149011612, 0.10212633013725281, 0.0, 0.10000000149011612, 0.31702667474746704, 0.11507298797369003, 0.15974150598049164, 0.0, 0.10000000149011612, 0.0, 0.15941840410232544, 0.10000000149011612, 0.0, 0.14891895651817322, 0.10000000149011612, 0.0, 0.12319605052471161, 0.10000000149011612, 0.10000000149011612, 0.0, 0.17948207259178162, 0.10000000149011612, 0.23218180239200592, 0.10000000149011612, 0.0, 0.11184775829315186, 0.10000000149011612, 0.26520049571990967, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.1498347818851471, 0.0, 0.0, 0.10000000149011612, 0.0, 0.1529216766357422, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.11664845794439316, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2180103063583374, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.1315123587846756, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.15711647272109985], "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.pow_15", "trainable": true, "dtype": "float32", "function": "math.pow"}, "name": "tf.math.pow_15", "inbound_nodes": [["tf.math.subtract_15", 0, 0, {"y": 2, "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_sum_15", "trainable": true, "dtype": "float32", "function": "math.reduce_sum"}, "name": "tf.math.reduce_sum_15", "inbound_nodes": [["tf.math.pow_15", 0, 0, {"axis": -1}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_mean_15", "trainable": true, "dtype": "float32", "function": "math.reduce_mean"}, "name": "tf.math.reduce_mean_15", "inbound_nodes": [["tf.math.reduce_sum_15", 0, 0, {}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.__operators__.add_15", "trainable": true, "dtype": "float32", "function": "__operators__.add"}, "name": "tf.__operators__.add_15", "inbound_nodes": [["tf.math.reduce_mean_15", 0, 0, {"y": 7.484910881519317e-05, "name": null}]]}, {"class_name": "AddLoss", "config": {"name": "add_loss_15", "trainable": true, "dtype": "float32", "unconditional": false}, "name": "add_loss_15", "inbound_nodes": [[["tf.__operators__.add_15", 0, 0, {}]]]}], "input_layers": [["input_16", 0, 0]], "output_layers": [["tf.math.reduce_sum_15", 0, 0]]}, "keras_version": "2.6.0", "backend": "tensorflow"}
{"class_name": "Functional", "config": {"name": "model_11", "layers": [{"class_name": "InputLayer", "config": {"batch_input_shape": [null, 2], "dtype": "float32", "sparse": false, "ragged": false, "name": "input_8"}, "name": "input_8", "inbound_nodes": []}, {"class_name": "Dense", "config": {"name": "dense_50", "trainable": true, "dtype": "float32", "units": 500, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_50", "inbound_nodes": [[["input_8", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "dense_51", "trainable": true, "dtype": "float32", "units": 2000, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_51", "inbound_nodes": [[["dense_50", 0, 0, {}]]]}, {"class_name": "Dropout", "config": {"name": "dropout_39", "trainable": true, "dtype": "float32", "rate": 0.2, "noise_shape": null, "seed": null}, "name": "dropout_39", "inbound_nodes": [[["dense_51", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "net_output", "trainable": true, "dtype": "float32", "units": 500, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "net_output", "inbound_nodes": [[["dropout_39", 0, 0, {}]]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.subtract_7", "trainable": true, "dtype": "float32", "function": "math.subtract"}, "name": "tf.math.subtract_7", "inbound_nodes": [["net_output", 0, 0, {"y": [0.0, 0.11124219745397568, 0.10000000149011612, 0.0, 0.15353906154632568, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.12437472492456436, 0.18796586990356445, 0.0, 0.10000000149011612, 0.10000000149011612, 0.1072223111987114, 0.0, 0.15026983618736267, 0.0, 0.12546320259571075, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.12369217723608017, 0.18175368010997772, 0.0, 0.21491442620754242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.0, 0.129632830619812, 0.0, 0.0, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.0, 0.12683062255382538, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.17843128740787506, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10633735358715057, 0.0, 0.15573255717754364, 0.10000000149011612, 0.1055401861667633, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10330907255411148, 0.15262389183044434, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.22187605500221252, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.10000000149011612, 0.11396222561597824, 0.1721600890159607, 0.0, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.234198659658432, 0.0, 0.10000000149011612, 0.0, 0.34273266792297363, 0.10000000149011612, 0.13370342552661896, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.12387203425168991, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.22546261548995972, 0.19392113387584686, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10460487753152847, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10987845808267593, 0.0, 0.10000000149011612, 0.1956743746995926, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.23793523013591766, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.23476271331310272, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.12119768559932709, 0.0, 0.20597025752067566, 0.0, 0.1480254828929901, 0.0, 0.0, 0.10000000149011612, 0.10585852712392807, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.3238820731639862, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.2188110649585724, 0.10000000149011612, 0.10000000149011612, 0.16148102283477783, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.11341933161020279, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.15596629679203033, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.22835247218608856, 0.10000000149011612, 0.10000000149011612, 0.0, 0.16528819501399994, 0.10000000149011612, 0.10000000149011612, 0.0, 0.15171606838703156, 0.0, 0.15476328134536743, 0.10000000149011612, 0.0, 0.3142812252044678, 0.10000000149011612, 0.0, 0.2615085542201996, 0.0, 0.2254134863615036, 0.10000000149011612, 0.10151176899671555, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.12577256560325623, 0.13640327751636505, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.3490942418575287, 0.0, 0.10000000149011612, 0.10000000149011612, 0.21290379762649536, 0.25673145055770874, 0.10000000149011612, 0.12337033450603485, 0.0, 0.0, 0.10000000149011612, 0.0, 0.1427372246980667, 0.0, 0.21045702695846558, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.15465693175792694, 0.2107481062412262, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1423456221818924, 0.10000000149011612, 0.10000000149011612, 0.16490861773490906, 0.10000000149011612, 0.11907795071601868, 0.0, 0.10000000149011612, 0.10000000149011612, 0.15261918306350708, 0.11549250036478043, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.2111085057258606, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.20751652121543884, 0.20248153805732727, 0.188946932554245, 0.10000000149011612, 0.11742876470088959, 0.10000000149011612, 0.0, 0.12651875615119934, 0.10000000149011612, 0.10000000149011612, 0.19383350014686584, 0.12206726521253586, 0.10000000149011612, 0.10000000149011612, 0.0, 0.23252417147159576, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.2347816675901413, 0.0, 0.23295068740844727, 0.10000000149011612, 0.31954288482666016, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.12474875897169113, 0.10000000149011612, 0.10000000149011612, 0.1287429928779602, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.24647340178489685, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.32790759205818176, 0.10000000149011612, 0.10000000149011612, 0.14127108454704285, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.13158884644508362, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.15820127725601196, 0.10000000149011612, 0.19411760568618774, 0.12767210602760315, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.11758290976285934, 0.10125081986188889, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.17038403451442719, 0.10000000149011612, 0.12295742332935333, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.11597064882516861, 0.10000000149011612, 0.10669867694377899, 0.15235479176044464, 0.17433974146842957, 0.10000000149011612, 0.11181695759296417, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.2579447031021118, 0.0, 0.23256915807724, 0.10736517608165741, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.11746783554553986, 0.10000000149011612, 0.21774818003177643, 0.14662271738052368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.12290872633457184], "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.pow_7", "trainable": true, "dtype": "float32", "function": "math.pow"}, "name": "tf.math.pow_7", "inbound_nodes": [["tf.math.subtract_7", 0, 0, {"y": 2, "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_sum_7", "trainable": true, "dtype": "float32", "function": "math.reduce_sum"}, "name": "tf.math.reduce_sum_7", "inbound_nodes": [["tf.math.pow_7", 0, 0, {"axis": -1}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_mean_7", "trainable": true, "dtype": "float32", "function": "math.reduce_mean"}, "name": "tf.math.reduce_mean_7", "inbound_nodes": [["tf.math.reduce_sum_7", 0, 0, {}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.__operators__.add_7", "trainable": true, "dtype": "float32", "function": "__operators__.add"}, "name": "tf.__operators__.add_7", "inbound_nodes": [["tf.math.reduce_mean_7", 0, 0, {"y": 5.858125615119934e-05, "name": null}]]}, {"class_name": "AddLoss", "config": {"name": "add_loss_7", "trainable": true, "dtype": "float32", "unconditional": false}, "name": "add_loss_7", "inbound_nodes": [[["tf.__operators__.add_7", 0, 0, {}]]]}], "input_layers": [["input_8", 0, 0]], "output_layers": [["tf.math.reduce_sum_7", 0, 0]]}, "keras_version": "2.6.0", "backend": "tensorflow"}
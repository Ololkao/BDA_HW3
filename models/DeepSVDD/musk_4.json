{"class_name": "Functional", "config": {"name": "model_29", "layers": [{"class_name": "InputLayer", "config": {"batch_input_shape": [null, 2], "dtype": "float32", "sparse": false, "ragged": false, "name": "input_20"}, "name": "input_20", "inbound_nodes": []}, {"class_name": "Dense", "config": {"name": "dense_128", "trainable": true, "dtype": "float32", "units": 830, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_128", "inbound_nodes": [[["input_20", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "dense_129", "trainable": true, "dtype": "float32", "units": 3320, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_129", "inbound_nodes": [[["dense_128", 0, 0, {}]]]}, {"class_name": "Dropout", "config": {"name": "dropout_99", "trainable": true, "dtype": "float32", "rate": 0.2, "noise_shape": null, "seed": null}, "name": "dropout_99", "inbound_nodes": [[["dense_129", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "net_output", "trainable": true, "dtype": "float32", "units": 830, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "net_output", "inbound_nodes": [[["dropout_99", 0, 0, {}]]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.subtract_19", "trainable": true, "dtype": "float32", "function": "math.subtract"}, "name": "tf.math.subtract_19", "inbound_nodes": [["net_output", 0, 0, {"y": [0.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.25645366311073303, 0.0, 0.10000000149011612, 0.1156165599822998, 0.10000000149011612, 0.0, 0.33285242319107056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2418612539768219, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.17247280478477478, 0.23944805562496185, 0.10000000149011612, 0.49941059947013855, 0.10000000149011612, 0.0, 0.0, 0.0, 0.322687566280365, 0.10000000149011612, 0.10000000149011612, 0.7073892951011658, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.47277987003326416, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.3320774435997009, 0.3209160566329956, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.301228404045105, 0.0, 0.23512502014636993, 0.25585877895355225, 0.0, 0.10000000149011612, 0.0, 0.4959254264831543, 0.10000000149011612, 0.333656370639801, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.13591237366199493, 0.2172844111919403, 0.1315392702817917, 0.12746621668338776, 0.1350095570087433, 0.0, 0.1330539584159851, 0.25090572237968445, 0.23564960062503815, 0.35854998230934143, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.3241686224937439, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1826554387807846, 0.10000000149011612, 0.10000000149011612, 0.11836977303028107, 0.11789500713348389, 0.0, 0.0, 0.10260094702243805, 0.1562100499868393, 0.13566215336322784, 0.10000000149011612, 0.2250818908214569, 0.10000000149011612, 0.10000000149011612, 0.0, 0.163077250123024, 0.0, 0.0, 0.12597127258777618, 0.10000000149011612, 0.3208506405353546, 0.256559818983078, 0.10000000149011612, 0.0, 0.12923678755760193, 0.12578359246253967, 0.17948724329471588, 0.15875756740570068, 0.0, 0.0, 0.1833600401878357, 0.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.12416762858629227, 0.10000000149011612, 0.0, 0.0, 0.0, 0.10000000149011612, 0.0, 0.0, 0.16504500806331635, 0.10000000149011612, 0.42760807275772095, 0.10000000149011612, 0.10000000149011612, 0.0, 0.15894271433353424, 0.0, 0.13346613943576813, 0.16259628534317017, 0.12687468528747559, 0.10736531764268875, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.1283854842185974, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2224496304988861, 0.0, 0.15952906012535095, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.21001483500003815, 0.27344679832458496, 0.1928185075521469, 0.0, 0.16070277988910675, 0.1854071319103241, 0.2505260407924652, 0.10000000149011612, 0.10000000149011612, 0.10632849484682083, 0.1531473845243454, 0.1858401596546173, 0.10063060373067856, 0.4328513741493225, 0.15716184675693512, 0.0, 0.17256410419940948, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.3656715750694275, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.5456039905548096, 0.0, 0.2185821235179901, 0.10000000149011612, 0.10000000149011612, 0.2260802686214447, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.2652643322944641, 0.10000000149011612, 0.17810308933258057, 0.1043502539396286, 0.6296439170837402, 0.18513987958431244, 0.0, 0.0, 0.17985452711582184, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.27402493357658386, 0.22529523074626923, 0.0, 0.10000000149011612, 0.1561451256275177, 0.2475554645061493, 0.0, 0.10000000149011612, 0.10000000149011612, 0.7176997661590576, 0.1326693743467331, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.17308180034160614, 0.10616081953048706, 0.12897111475467682, 0.10000000149011612, 0.0, 0.0, 0.2563753128051758, 0.0, 0.41557392477989197, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37988489866256714, 0.4483843147754669, 0.1683826446533203, 0.10000000149011612, 0.24009065330028534, 0.0, 0.10000000149011612, 0.0, 0.2468920648097992, 0.10000000149011612, 0.0, 0.0, 0.28409549593925476, 0.26895517110824585, 0.17661580443382263, 0.4132762849330902, 0.24384155869483948, 0.3375391960144043, 0.0, 0.10076037794351578, 0.0, 0.10000000149011612, 0.14005640149116516, 0.11423680186271667, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.11739672720432281, 0.10000000149011612, 0.33938050270080566, 0.10906416922807693, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.25273674726486206, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.3559362292289734, 0.0, 0.0, 0.3830796778202057, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.21008098125457764, 0.0, 0.0, 0.0, 0.17173832654953003, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.3174769878387451, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.13334187865257263, 0.10000000149011612, 0.10000000149011612, 0.12637051939964294, 0.1718732714653015, 0.10000000149011612, 0.0, 0.18017645180225372, 0.2588135004043579, 0.10987835377454758, 0.23354925215244293, 0.10000000149011612, 0.22704991698265076, 0.12571297585964203, 0.10941405594348907, 0.15526486933231354, 0.20029178261756897, 0.3390680253505707, 0.0, 0.10000000149011612, 0.3014514148235321, 0.167006716132164, 0.10622084140777588, 0.10000000149011612, 0.25759291648864746, 0.10000000149011612, 0.0, 0.0, 0.0, 0.34079453349113464, 0.10898008197546005, 0.20791763067245483, 0.0, 0.0, 0.28044015169143677, 0.0, 0.10000000149011612, 0.0, 0.105193592607975, 0.14722707867622375, 0.0, 0.17455632984638214, 0.0, 0.0, 0.0, 0.4270630478858948, 0.0, 0.10000000149011612, 0.3706369996070862, 0.0, 0.10000000149011612, 0.10892583429813385, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.41969695687294006, 0.26544979214668274, 0.30385008454322815, 0.45138952136039734, 0.14441750943660736, 0.10000000149011612, 0.11316456645727158, 0.0, 0.3184911012649536, 0.4920661747455597, 0.13711857795715332, 0.12484590709209442, 0.0, 0.4999440014362335, 0.10000000149011612, 0.0, 0.0, 0.2014966905117035, 0.10465232282876968, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.23074884712696075, 0.10000000149011612, 0.14995639026165009, 0.10000000149011612, 0.18849965929985046, 0.24495433270931244, 0.10000000149011612, 0.10489843785762787, 0.10000000149011612, 0.0, 0.22811047732830048, 0.10000000149011612, 0.10000000149011612, 0.2840881645679474, 0.18933944404125214, 0.2919461727142334, 0.10000000149011612, 0.0, 0.0, 0.2480200231075287, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10414280742406845, 0.0, 0.10000000149011612, 0.17799046635627747, 0.2967057228088379, 0.0, 0.0, 0.3802827000617981, 0.2701278030872345, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.13625988364219666, 0.10000000149011612, 0.0, 0.10000000149011612, 0.1666967123746872, 0.10000000149011612, 0.0, 0.0, 0.0, 0.2697497606277466, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.16695435345172882, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.21495933830738068, 0.4325016438961029, 0.10420560836791992, 0.21591398119926453, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.3652431070804596, 0.1880759596824646, 0.0, 0.18932616710662842, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.233724445104599, 0.10931355506181717, 0.17605938017368317, 0.10000000149011612, 0.0, 0.0, 0.26661235094070435, 0.10000000149011612, 0.20066875219345093, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.13420575857162476, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.45131853222846985, 0.2229945808649063, 0.10000000149011612, 0.10000000149011612, 0.163455531001091, 0.30043837428092957, 0.19133125245571136, 0.0, 0.0, 0.0, 0.10000000149011612, 0.4414275288581848, 0.0, 0.0, 0.0, 0.2389814704656601, 0.0, 0.0, 0.3441893458366394, 0.18638265132904053, 0.3788686990737915, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.21081918478012085, 0.10000000149011612, 0.0, 0.10000000149011612, 0.22028812766075134, 0.10000000149011612, 0.17121154069900513, 0.10000000149011612, 0.10000000149011612, 0.0, 0.2199135422706604, 0.10000000149011612, 0.11117184162139893, 0.0, 0.17962197959423065, 0.14579425752162933, 0.0, 0.10000000149011612, 0.10000000149011612, 0.29355865716934204, 0.30576276779174805, 0.10000000149011612, 0.0, 0.4402267038822174, 0.424958199262619, 0.0, 0.4358169734477997, 0.10000000149011612, 0.16419003903865814, 0.3068804144859314, 0.0, 0.0, 0.0, 0.3490460216999054, 0.3331470489501953, 0.10000000149011612, 0.10000000149011612, 0.21376730501651764, 0.20228074491024017, 0.15637074410915375, 0.0, 0.10000000149011612, 0.0, 0.0, 0.16473037004470825, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2610551416873932, 0.26213064789772034, 0.25446298718452454, 0.0, 0.0, 0.10000000149011612, 0.18214121460914612, 0.0, 0.1543351113796234, 0.27768418192863464, 0.0, 0.18679344654083252, 0.4033373296260834, 0.10000000149011612, 0.40037983655929565, 0.0, 0.0, 0.10000000149011612, 0.0, 0.21857905387878418, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.16513238847255707, 0.17512653768062592, 0.10734234005212784, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.26314860582351685, 0.10990211367607117, 0.0, 0.3304421603679657, 0.28876978158950806, 0.13536810874938965, 0.7673645615577698, 0.10000000149011612, 0.14704373478889465, 0.10000000149011612, 0.21111364662647247, 0.0, 0.10000000149011612, 0.0, 0.0, 0.544079065322876, 0.0, 0.0, 0.23558497428894043, 0.10000000149011612, 0.0, 0.10000000149011612, 0.1485389769077301, 0.0, 0.0, 0.0, 0.5309602618217468, 0.10000000149011612, 0.38260582089424133, 0.0, 0.24218642711639404, 0.5073735117912292, 0.3507175147533417, 0.0, 0.4623781740665436, 0.0, 0.10000000149011612, 0.0, 0.16096080839633942, 0.23237036168575287, 0.0, 0.5495266914367676, 0.1390317976474762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32614490389823914, 0.10000000149011612, 0.0, 0.10000000149011612, 0.15885648131370544, 0.2117154896259308, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.24600253999233246, 0.0, 0.10000000149011612, 0.14400602877140045, 0.0, 0.10000000149011612, 0.0, 0.4384956359863281, 0.10000000149011612, 0.0, 0.2422606647014618, 0.0, 0.0, 0.0, 0.4015992283821106, 0.17166435718536377, 0.10000000149011612, 0.144118994474411, 0.0, 0.0, 0.0, 0.0, 0.2808849811553955, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.43543633818626404, 0.10000000149011612, 0.13462448120117188, 0.24728575348854065, 0.10000000149011612, 0.615079402923584, 0.14136825501918793, 0.2365189492702484, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.15700583159923553, 0.0, 0.0, 0.3140302002429962, 0.10000000149011612, 0.10000000149011612, 0.24574510753154755, 0.23783552646636963, 0.11119869351387024, 0.0, 0.10000000149011612, 0.0, 0.1688753366470337, 0.0, 0.10000000149011612, 0.13765020668506622, 0.1977653205394745, 0.0, 0.10000000149011612, 0.1724657267332077, 0.25882935523986816, 0.0, 0.5679517984390259, 0.0, 0.12290715426206589, 0.10000000149011612, 0.16437554359436035, 0.3473832309246063, 0.10000000149011612, 0.2848942279815674, 0.0, 0.10000000149011612, 0.0, 0.1468740850687027, 0.10000000149011612, 0.0, 0.14581581950187683, 0.0, 0.0, 0.1869295984506607, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.20326896011829376, 0.10000000149011612, 0.17166586220264435, 0.10000000149011612, 0.0, 0.12986640632152557, 0.12664079666137695, 0.287203311920166, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.12420761585235596, 0.0, 0.0, 0.0, 0.10000000149011612, 0.18280786275863647, 0.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.0, 0.174167662858963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.1758725643157959], "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.pow_19", "trainable": true, "dtype": "float32", "function": "math.pow"}, "name": "tf.math.pow_19", "inbound_nodes": [["tf.math.subtract_19", 0, 0, {"y": 2, "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_sum_19", "trainable": true, "dtype": "float32", "function": "math.reduce_sum"}, "name": "tf.math.reduce_sum_19", "inbound_nodes": [["tf.math.pow_19", 0, 0, {"axis": -1}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_mean_19", "trainable": true, "dtype": "float32", "function": "math.reduce_mean"}, "name": "tf.math.reduce_mean_19", "inbound_nodes": [["tf.math.reduce_sum_19", 0, 0, {}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.__operators__.add_19", "trainable": true, "dtype": "float32", "function": "__operators__.add"}, "name": "tf.__operators__.add_19", "inbound_nodes": [["tf.math.reduce_mean_19", 0, 0, {"y": 7.484910881519317e-05, "name": null}]]}, {"class_name": "AddLoss", "config": {"name": "add_loss_19", "trainable": true, "dtype": "float32", "unconditional": false}, "name": "add_loss_19", "inbound_nodes": [[["tf.__operators__.add_19", 0, 0, {}]]]}], "input_layers": [["input_20", 0, 0]], "output_layers": [["tf.math.reduce_sum_19", 0, 0]]}, "keras_version": "2.6.0", "backend": "tensorflow"}
{"class_name": "Functional", "config": {"name": "model_17", "layers": [{"class_name": "InputLayer", "config": {"batch_input_shape": [null, 2], "dtype": "float32", "sparse": false, "ragged": false, "name": "input_12"}, "name": "input_12", "inbound_nodes": []}, {"class_name": "Dense", "config": {"name": "dense_76", "trainable": true, "dtype": "float32", "units": 830, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_76", "inbound_nodes": [[["input_12", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "dense_77", "trainable": true, "dtype": "float32", "units": 3320, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "dense_77", "inbound_nodes": [[["dense_76", 0, 0, {}]]]}, {"class_name": "Dropout", "config": {"name": "dropout_59", "trainable": true, "dtype": "float32", "rate": 0.2, "noise_shape": null, "seed": null}, "name": "dropout_59", "inbound_nodes": [[["dense_77", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "net_output", "trainable": true, "dtype": "float32", "units": 830, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": {"class_name": "L2", "config": {"l2": 0.10000000149011612}}, "kernel_constraint": null, "bias_constraint": null}, "name": "net_output", "inbound_nodes": [[["dropout_59", 0, 0, {}]]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.subtract_11", "trainable": true, "dtype": "float32", "function": "math.subtract"}, "name": "tf.math.subtract_11", "inbound_nodes": [["net_output", 0, 0, {"y": [0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.28943151235580444, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.27126842737197876, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.21020054817199707, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.17151063680648804, 0.2385832667350769, 0.10000000149011612, 0.43535104393959045, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.3017278015613556, 0.10000000149011612, 0.10000000149011612, 0.5452811121940613, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.4285643994808197, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.0, 0.12915270030498505, 0.29544374346733093, 0.30749383568763733, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.266921728849411, 0.0, 0.19716580212116241, 0.17414380609989166, 0.0, 0.10000000149011612, 0.0, 0.4111858308315277, 0.10000000149011612, 0.24572277069091797, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.22541432082653046, 0.11062214523553848, 0.1321556270122528, 0.10000000149011612, 0.0, 0.13314563035964966, 0.22309502959251404, 0.18208681046962738, 0.28780287504196167, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.2657228708267212, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.13110288977622986, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1326308697462082, 0.0, 0.0, 0.10000000149011612, 0.14445534348487854, 0.18812841176986694, 0.10000000149011612, 0.19846591353416443, 0.10000000149011612, 0.10000000149011612, 0.0, 0.1890213042497635, 0.10000000149011612, 0.0, 0.13329777121543884, 0.10000000149011612, 0.22546882927417755, 0.16844569146633148, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.17103567719459534, 0.10432799160480499, 0.10000000149011612, 0.0, 0.15089380741119385, 0.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10158201307058334, 0.10000000149011612, 0.0, 0.0, 0.0, 0.10896576941013336, 0.0, 0.0, 0.1389939934015274, 0.10000000149011612, 0.3913770318031311, 0.10000000149011612, 0.10000000149011612, 0.0, 0.16613100469112396, 0.0, 0.12801973521709442, 0.1330491602420807, 0.1164756566286087, 0.11235576122999191, 0.10000000149011612, 0.1476733237504959, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10591394454240799, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1542731374502182, 0.0, 0.13477903604507446, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.20220431685447693, 0.2517513334751129, 0.1750364452600479, 0.10000000149011612, 0.1264415830373764, 0.1455821841955185, 0.2231922298669815, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.1782514452934265, 0.1711747795343399, 0.10000000149011612, 0.3707480728626251, 0.10000000149011612, 0.0, 0.11344374716281891, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.3585497736930847, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.517944872379303, 0.0, 0.25978004932403564, 0.10000000149011612, 0.10000000149011612, 0.19079433381557465, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.24539345502853394, 0.10000000149011612, 0.13002845644950867, 0.10000000149011612, 0.5812004208564758, 0.15316890180110931, 0.0, 0.10000000149011612, 0.15399016439914703, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.26241058111190796, 0.20935919880867004, 0.0, 0.10000000149011612, 0.12148449569940567, 0.20129500329494476, 0.0, 0.10000000149011612, 0.10000000149011612, 0.6547832489013672, 0.1251884251832962, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.19172000885009766, 0.10000000149011612, 0.18031564354896545, 0.10000000149011612, 0.0, 0.10000000149011612, 0.24492591619491577, 0.10000000149011612, 0.44828468561172485, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.0, 0.0, 0.323972225189209, 0.37367549538612366, 0.1788226217031479, 0.10000000149011612, 0.23772455751895905, 0.0, 0.10000000149011612, 0.0, 0.19659608602523804, 0.10000000149011612, 0.0, 0.10000000149011612, 0.19232194125652313, 0.19717831909656525, 0.22308722138404846, 0.3426361382007599, 0.2896367311477661, 0.3015681803226471, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10478422790765762, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.13747656345367432, 0.10000000149011612, 0.29282352328300476, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10015355050563812, 0.23657305538654327, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.34606412053108215, 0.0, 0.0, 0.3655003011226654, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.13119058310985565, 0.0, 0.0, 0.0, 0.20326657593250275, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.2589046061038971, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.15013323724269867, 0.10000000149011612, 0.10000000149011612, 0.1313806176185608, 0.16007186472415924, 0.10000000149011612, 0.0, 0.10675472766160965, 0.21229934692382812, 0.10000000149011612, 0.28424957394599915, 0.10000000149011612, 0.20432355999946594, 0.1371341347694397, 0.10000000149011612, 0.1498972326517105, 0.15869012475013733, 0.30061474442481995, 0.0, 0.12448655813932419, 0.28816214203834534, 0.10000000149011612, 0.10608961433172226, 0.10000000149011612, 0.19331753253936768, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.284976989030838, 0.13185890018939972, 0.14793236553668976, 0.10000000149011612, 0.0, 0.23606783151626587, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10330097377300262, 0.10000000149011612, 0.0, 0.11009301990270615, 0.10000000149011612, 0.10000000149011612, 0.0, 0.3896854519844055, 0.10000000149011612, 0.10000000149011612, 0.3038652241230011, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.45771870017051697, 0.23873718082904816, 0.2162943333387375, 0.34123989939689636, 0.1583959013223648, 0.10000000149011612, 0.1135958731174469, 0.0, 0.24836237728595734, 0.3852299451828003, 0.1260181963443756, 0.10000000149011612, 0.10000000149011612, 0.42468076944351196, 0.10000000149011612, 0.0, 0.0, 0.13802176713943481, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.1519595980644226, 0.10000000149011612, 0.15197888016700745, 0.10000000149011612, 0.16269244253635406, 0.20198127627372742, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.19122591614723206, 0.10885700583457947, 0.10000000149011612, 0.2917647361755371, 0.1922663450241089, 0.2181997001171112, 0.10000000149011612, 0.0, 0.10000000149011612, 0.19011248648166656, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.11041774600744247, 0.0, 0.10000000149011612, 0.11303071677684784, 0.31215420365333557, 0.0, 0.0, 0.3435884714126587, 0.2783252000808716, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.13201382756233215, 0.10000000149011612, 0.0, 0.12934117019176483, 0.10000000149011612, 0.0, 0.0, 0.0, 0.33006876707077026, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.12017925083637238, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.17246219515800476, 0.3583120107650757, 0.11229276657104492, 0.17737434804439545, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10067957639694214, 0.3342272639274597, 0.16493503749370575, 0.0, 0.21389715373516083, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.16170340776443481, 0.12659145891666412, 0.11631719022989273, 0.10000000149011612, 0.10000000149011612, 0.0, 0.24796801805496216, 0.10000000149011612, 0.18652226030826569, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.17258650064468384, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.37489867210388184, 0.23297829926013947, 0.10000000149011612, 0.10000000149011612, 0.18899603188037872, 0.19988428056240082, 0.16154417395591736, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.41880637407302856, 0.0, 0.0, 0.0, 0.1998685598373413, 0.10000000149011612, 0.0, 0.2750879228115082, 0.19114454090595245, 0.328262060880661, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.16727417707443237, 0.10000000149011612, 0.0, 0.10000000149011612, 0.17958249151706696, 0.10000000149011612, 0.15022751688957214, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2551162540912628, 0.10000000149011612, 0.10000000149011612, 0.0, 0.15090474486351013, 0.14241546392440796, 0.0, 0.10000000149011612, 0.10000000149011612, 0.23982484638690948, 0.27752193808555603, 0.10000000149011612, 0.0, 0.3930404782295227, 0.3374825716018677, 0.0, 0.320743203163147, 0.10000000149011612, 0.12538708746433258, 0.20206937193870544, 0.10000000149011612, 0.10000000149011612, 0.0, 0.35734954476356506, 0.25088435411453247, 0.10000000149011612, 0.10000000149011612, 0.12752942740917206, 0.17841926217079163, 0.15798038244247437, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10899618268013, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.20849567651748657, 0.2353830486536026, 0.23542827367782593, 0.0, 0.0, 0.10000000149011612, 0.12294220924377441, 0.0, 0.12145072966814041, 0.2173861712217331, 0.10000000149011612, 0.18247714638710022, 0.33812472224235535, 0.10000000149011612, 0.3055065870285034, 0.0, 0.0, 0.10000000149011612, 0.0, 0.16588035225868225, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.11322713643312454, 0.14180085062980652, 0.1423194408416748, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.22381103038787842, 0.15796537697315216, 0.10000000149011612, 0.2787851393222809, 0.20497873425483704, 0.10186829417943954, 0.6901881694793701, 0.10000000149011612, 0.1369214951992035, 0.10000000149011612, 0.16278088092803955, 0.0, 0.10000000149011612, 0.0, 0.0, 0.5149925351142883, 0.0, 0.10000000149011612, 0.21716906130313873, 0.10000000149011612, 0.0, 0.10000000149011612, 0.2154090702533722, 0.10000000149011612, 0.10000000149011612, 0.0, 0.5377957224845886, 0.10000000149011612, 0.2932237982749939, 0.10000000149011612, 0.13791432976722717, 0.4461310803890228, 0.27909055352211, 0.0, 0.36652034521102905, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.22428688406944275, 0.10000000149011612, 0.4693160355091095, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26047009229660034, 0.10000000149011612, 0.0, 0.10000000149011612, 0.1698841154575348, 0.1468636393547058, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.20014658570289612, 0.0, 0.10000000149011612, 0.22208835184574127, 0.0, 0.10000000149011612, 0.0, 0.39209750294685364, 0.10000000149011612, 0.0, 0.26101991534233093, 0.10000000149011612, 0.10000000149011612, 0.0, 0.313710480928421, 0.15850532054901123, 0.10000000149011612, 0.18013399839401245, 0.0, 0.0, 0.0, 0.0, 0.22822943329811096, 0.10171262919902802, 0.0, 0.0, 0.10000000149011612, 0.3952305316925049, 0.10000000149011612, 0.10335620492696762, 0.22151371836662292, 0.10000000149011612, 0.5226582288742065, 0.16768522560596466, 0.15023067593574524, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.24654634296894073, 0.10000000149011612, 0.10000000149011612, 0.2498795986175537, 0.2165268361568451, 0.10000000149011612, 0.0, 0.10000000149011612, 0.10000000149011612, 0.14253361523151398, 0.0, 0.10799790918827057, 0.15146464109420776, 0.16611672937870026, 0.0, 0.10000000149011612, 0.12797366082668304, 0.21123157441616058, 0.0, 0.5041415691375732, 0.10000000149011612, 0.11716800928115845, 0.10000000149011612, 0.10858484357595444, 0.32418254017829895, 0.10000000149011612, 0.1975046992301941, 0.0, 0.10000000149011612, 0.0, 0.13879038393497467, 0.10000000149011612, 0.0, 0.1353282928466797, 0.10000000149011612, 0.0, 0.14489765465259552, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.19056762754917145, 0.10000000149011612, 0.19832274317741394, 0.10000000149011612, 0.0, 0.10527374595403671, 0.10000000149011612, 0.2608775496482849, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.16023971140384674, 0.0, 0.0, 0.10000000149011612, 0.0, 0.17361821234226227, 0.0, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.11035589128732681, 0.0, 0.11768828332424164, 0.10000000149011612, 0.10000000149011612, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.0, 0.1820836365222931, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.0, 0.10000000149011612, 0.12366470694541931, 0.10000000149011612, 0.0, 0.10000000149011612, 0.0, 0.1651914417743683], "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.pow_11", "trainable": true, "dtype": "float32", "function": "math.pow"}, "name": "tf.math.pow_11", "inbound_nodes": [["tf.math.subtract_11", 0, 0, {"y": 2, "name": null}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_sum_11", "trainable": true, "dtype": "float32", "function": "math.reduce_sum"}, "name": "tf.math.reduce_sum_11", "inbound_nodes": [["tf.math.pow_11", 0, 0, {"axis": -1}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.math.reduce_mean_11", "trainable": true, "dtype": "float32", "function": "math.reduce_mean"}, "name": "tf.math.reduce_mean_11", "inbound_nodes": [["tf.math.reduce_sum_11", 0, 0, {}]]}, {"class_name": "TFOpLambda", "config": {"name": "tf.__operators__.add_11", "trainable": true, "dtype": "float32", "function": "__operators__.add"}, "name": "tf.__operators__.add_11", "inbound_nodes": [["tf.math.reduce_mean_11", 0, 0, {"y": 7.484910881519317e-05, "name": null}]]}, {"class_name": "AddLoss", "config": {"name": "add_loss_11", "trainable": true, "dtype": "float32", "unconditional": false}, "name": "add_loss_11", "inbound_nodes": [[["tf.__operators__.add_11", 0, 0, {}]]]}], "input_layers": [["input_12", 0, 0]], "output_layers": [["tf.math.reduce_sum_11", 0, 0]]}, "keras_version": "2.6.0", "backend": "tensorflow"}